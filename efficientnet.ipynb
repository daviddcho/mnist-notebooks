{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "controversial-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "parse = lambda file: np.frombuffer(gzip.open(file).read(), dtype=np.uint8).copy()\n",
    "X_train = parse(\"data/MNIST/raw/train-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "Y_train = parse(\"data/MNIST/raw/train-labels-idx1-ubyte.gz\")[8:]\n",
    "X_test = parse(\"data/MNIST/raw/t10k-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
    "Y_test = parse(\"data/MNIST/raw/t10k-labels-idx1-ubyte.gz\")[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "entertaining-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "def fetch(url):\n",
    "  import requests, os, hashlib, tempfile\n",
    "  fp = os.path.join(tempfile.gettempdir(), hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "  if os.path.isfile(fp) and os.stat(fp).st_size > 0:\n",
    "    with open(fp, \"rb\") as f:\n",
    "      dat = f.read()\n",
    "  else:\n",
    "    print(\"fetching %s\" % url)\n",
    "    dat = requests.get(url).content\n",
    "    with open(fp+\".tmp\", \"wb\") as f:\n",
    "      f.write(dat)\n",
    "    os.rename(fp+\".tmp\", fp)\n",
    "  return dat\n",
    "\n",
    "def load_cifar():\n",
    "  tt = tarfile.open(fileobj=io.BytesIO(fetch(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\")), mode=\"r:gz\")\n",
    "  db = pickle.load(tt.extractfile(\"cifar-10-batches-py/data_batch_1\"), encoding=\"bytes\")\n",
    "  X = db[b'data'].reshape((-1, 3, 32, 32))\n",
    "  Y = np.array(db[b'labels'])\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "animated-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import math\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "interracial-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConvBlock(nn.Module):\n",
    "  \"\"\"Mobile Inverted Residual Bottleneck Block\"\"\"\n",
    "  def __init__(self, kernel_size, strides, expand_ratio, input_filters, output_filters, se_ratio, has_se):\n",
    "    super(MBConvBlock, self).__init__()\n",
    "    oup = expand_ratio * input_filters\n",
    "    if expand_ratio != 1:\n",
    "      self._expand_conv = nn.Conv2d(in_channels=input_filters, out_channels=oup, kernel_size=1, bias=False)\n",
    "      self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=0.1, eps=1e-5)\n",
    "    else: \n",
    "      self._expand_conv = None\n",
    "    \n",
    "    self.strides = strides\n",
    "    if strides == (2,2):\n",
    "      self.pad = [(kernel_size-1)//2-1, (kernel_size-1)//2]*2\n",
    "    else:\n",
    "      self.pad = [(kernel_size-1)//2]*4\n",
    "    \n",
    "    k = kernel_size\n",
    "    s = self.strides\n",
    "    print(k, s)\n",
    "    self._depthwise_conv = nn.Conv2d(in_channels=oup, out_channels=oup, groups=oup, \n",
    "                                     kernel_size=k, stride=s, bias=False)\n",
    "    self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=0.1, eps=1e-5)\n",
    "    \n",
    "    self.has_se = has_se\n",
    "    if self.has_se: \n",
    "      num_squeezed_channels = max(1, int(input_filters * se_ratio))\n",
    "      self._se_reduce = nn.Conv2d(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "      self._se_expand = nn.Conv2d(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "    \n",
    "    self._project_conv = nn.Conv2d(in_channels=oup, out_channels=output_filters, kernel_size=1, bias=False)\n",
    "    self._bn2 = nn.BatchNorm2d(num_features=output_filters, momentum=0.1, eps=1e-5)\n",
    "    self._swish = nn.SiLU()\n",
    "    \n",
    "  def pad2d(self, x, padding):\n",
    "    return x[:, :, -padding[2]:x.shape[2]+padding[3], -padding[0]:x.shape[3]+padding[1]]\n",
    "  \n",
    "  def forward(self, inputs):\n",
    "    # Expansion and Depthwise Convolution\n",
    "    x = inputs \n",
    "    if self._expand_conv:\n",
    "      x = self._expand_conv(x)\n",
    "      x = self._bn0(x)\n",
    "      x = self._swish(x)\n",
    "    \n",
    "    print(x.shape)\n",
    "    #x = self.pad2d(x, self.pad)\n",
    "    print(x.shape)\n",
    "    x = self._depthwise_conv(x)\n",
    "    x = self._bn1(x)\n",
    "    x = self._swish(x)\n",
    "      \n",
    "    # Squeeze and Excitation\n",
    "    if self.has_se: \n",
    "      x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
    "      x_squeezed = self._se_reduce(x_squeezed)\n",
    "      x_squeezed = self._swish(x_squeezed)\n",
    "      x_squeezed = self._se_expand(x_squeezed)\n",
    "      x = torch.sigmoid(x_squeezed) * x\n",
    "      \n",
    "    # Pointwise Convolution\n",
    "    x = self._project_conv(x)\n",
    "    x = self._bn2(x)\n",
    "      \n",
    "    # Skip connection\n",
    "    if x.shape == inputs.shape: \n",
    "      x = x + inputs \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "owned-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "  def __init__(self, number=0, classes=1000, has_se=True):\n",
    "    super(EfficientNet, self).__init__()\n",
    "    self.number = number \n",
    "    global_params = [\n",
    "      # width, depth \n",
    "      (1.0, 1.0), # b0 \n",
    "      (1.0, 1.1), # b1 \n",
    "      (1.1, 1.2), # b2\n",
    "      (1.2, 1.4), # b3\n",
    "      (1.4, 1.8), # b4\n",
    "      (1.6, 2.2), # b5\n",
    "      (1.8, 2.6), # b6\n",
    "      (2.0, 3.1), # b7\n",
    "      (2.2, 3.6), # b8\n",
    "      (4.3, 5.3), # l2\n",
    "    ][number]\n",
    "    \n",
    "    def round_filters(filters):\n",
    "      \"\"\"Round number of filters based on depth multiplier\"\"\"\n",
    "      multiplier = global_params[0]\n",
    "      divisor = 8\n",
    "      filters *= multiplier \n",
    "      new_filters = max(divisor, int(filters + divisor/2) // divisor*divisor)\n",
    "      if new_filters < 0.9 * filters: # prevent rounding by more than 10%\n",
    "        new_filters += divisor\n",
    "      return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "      return int(math.ceil(global_params[1] * repeats))\n",
    "    \n",
    "    # Stem\n",
    "    in_channels = 3 # rgb\n",
    "    out_channels = round_filters(32)\n",
    "    self._conv_stem = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "    self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=0.1, eps=1e-5)\n",
    "    \n",
    "    # num_repeats, kernel_size, strides, expand_ratio, input_filters, output_filters, se_ratio\n",
    "    block_args = [\n",
    "      [1, 3, (1,1), 1, 32, 16, 0.25],\n",
    "      [2, 3, (2,2), 6, 16, 24, 0.25],\n",
    "      [2, 5, (2,2), 6, 24, 40, 0.25],\n",
    "      [3, 3, (2,2), 6, 40, 80, 0.25],\n",
    "      [3, 5, (1,1), 6, 80, 112, 0.25],\n",
    "      [4, 5, (2,2), 6, 112, 192, 0.25],\n",
    "      [1, 3, (1,1), 6, 192, 320, 0.25],\n",
    "    ]\n",
    "    self._blocks = []\n",
    "    # Build blocks\n",
    "    for b in block_args:\n",
    "      args = b[1:]\n",
    "      args[3] = round_filters(args[3])\n",
    "      args[4] = round_filters(args[4])\n",
    "      for n in range(round_repeats(b[0])):\n",
    "        self._blocks.append(MBConvBlock(*args, has_se=has_se))\n",
    "        args[3] = args[4]\n",
    "        args[1] = (1,1)\n",
    "    \n",
    "    # Head\n",
    "    in_channels = round_filters(320)\n",
    "    out_channels = round_filters(1280)\n",
    "    self._conv_head = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "    self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=0.1, eps=1e-5)\n",
    "    \n",
    "    # Final linear layer \n",
    "    self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "    self._dropout = nn.Dropout(0.2)\n",
    "    self._fc = nn.Linear(out_channels, classes)\n",
    "    self._swish = nn.SiLU()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    print(x.shape)\n",
    "    x = self._swish(self._bn0(self._conv_stem(x)))\n",
    "    for block in self._blocks:\n",
    "      x = block(x)\n",
    "    x = self._swish(self._bn1(self._conv_head(x)))\n",
    "    x = self._avg_pooling(x)\n",
    "    x = self._dropout(x)\n",
    "    x = self._fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "excessive-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "decent-joint",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (1, 1)\n",
      "3 (2, 2)\n",
      "3 (1, 1)\n",
      "5 (2, 2)\n",
      "5 (1, 1)\n",
      "3 (2, 2)\n",
      "3 (1, 1)\n",
      "3 (1, 1)\n",
      "5 (1, 1)\n",
      "5 (1, 1)\n",
      "5 (1, 1)\n",
      "5 (2, 2)\n",
      "5 (1, 1)\n",
      "5 (1, 1)\n",
      "5 (1, 1)\n",
      "3 (1, 1)\n",
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16, 32, 15, 15])\n",
      "torch.Size([16, 32, 15, 15])\n",
      "torch.Size([16, 96, 13, 13])\n",
      "torch.Size([16, 96, 13, 13])\n",
      "torch.Size([16, 144, 6, 6])\n",
      "torch.Size([16, 144, 6, 6])\n",
      "torch.Size([16, 144, 4, 4])\n",
      "torch.Size([16, 144, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-d2177664f0af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0msamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-ad7a7e213c54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_avg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-fd0e80cb36cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m#x = self.pad2d(x, self.pad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "BS = 16\n",
    "classes = 10\n",
    "model = EfficientNet(0, classes, has_se=False)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for i in (t := trange(5)):\n",
    "  samp = np.random.randint(0, X_train.shape[0], size=BS)\n",
    "  X = torch.tensor(X_train[samp]).float()\n",
    "  out = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "informed-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "# https://github.com/geohot/tinygrad/blob/9f732e697a39d561e90db3c91987f2ad442038e4/models/efficientnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hawaiian-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
